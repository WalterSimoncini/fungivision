{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd9a98d-9c15-4396-94e6-fbb61e9493f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Union\n",
    "from torch.nn.functional import normalize\n",
    "from torchvision.datasets import Flowers102\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from fungivision.wrapper import FUNGIWrapper\n",
    "from fungivision.config import KLConfig, DINOConfig, SimCLRConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ca8f9e-1c8d-4853-8566-00edf5647002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(format=\"[%(asctime)s:%(levelname)s]: %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e203cc5-11b3-4a30-ab17-3c7377f3fe92",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "We first define some utility functions in this section, such as the mean-per-class accuracy, which is the default evaluation metric for the Flowers102 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8743f69c-9a7a-4290-9ceb-179634abb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "\trandom.seed(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\n",
    "\tos.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341f4859-bbe2-45c8-9ac3-ab33541c5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_per_class_accuracy(preds: np.ndarray, targets: np.ndarray) -> float:\n",
    "   \"\"\"\n",
    "      Calculates the mean per class accuracy by calculating\n",
    "      the accuracy for each individual class and then averaging\n",
    "      them. See the link below for more details:\n",
    "\n",
    "      - https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class\n",
    "\n",
    "      Args:\n",
    "         preds (np.ndarray): the model predictions\n",
    "         targets (np.ndarray): the ground truth targets\n",
    "\n",
    "      Returns:\n",
    "         float: the mean-per-class accuracy metric\n",
    "   \"\"\"\n",
    "   mat = confusion_matrix(preds, targets)\n",
    "\n",
    "   # Summing over rows results in the total number of elements for each class.\n",
    "   # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "   class_sums = mat.sum(axis=0)\n",
    "   per_class_accuracy = mat.diagonal() / class_sums\n",
    "\n",
    "   return per_class_accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf07f4b-2431-4ae7-88ac-9ceb6ec10423",
   "metadata": {},
   "source": [
    "## FUNGI\n",
    "\n",
    "We first define a function to extract FUNGI features and the generic feature extraction parameters (batch size, dataset cache, ..). We then initialize a DINOv1 model and extract FUNGI features for the KL, DINO and SimCLR objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7571da82-e4dd-43a0-8348-af4108411954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fungi_features(\n",
    "    wrapper: FUNGIWrapper,\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    num_workers: int = 18\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    gradients, targets = [], []\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        # This makes sure each iteration returns a list of images and a list of targets,\n",
    "        # without the data loader creating a batch by itself\n",
    "        collate_fn=lambda batch: zip(*batch)\n",
    "    )\n",
    "\n",
    "    for images, batch_targets in tqdm(data_loader):\n",
    "        targets.append(torch.tensor(batch_targets))\n",
    "        gradients.append(wrapper(images).cpu().float())\n",
    "\n",
    "    return normalize(torch.cat(gradients, dim=0), dim=-1), torch.cat(targets, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5965c5a-9cda-4740-be16-675b2bb96708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    num_workers: int = 18\n",
    "):\n",
    "    features, targets = [], []\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=True):\n",
    "        with torch.no_grad():\n",
    "            for images, batch_targets in tqdm(data_loader):\n",
    "                images = images.to(device)\n",
    "        \n",
    "                targets.append(torch.tensor(batch_targets))\n",
    "                features.append(model(images).cpu().float())\n",
    "\n",
    "    return torch.cat(features, dim=0), torch.cat(targets, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc956d5c-932f-4e51-87b0-b9f0614c3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "seed_everything(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4e4280-e707-46d8-b331-8aea0392ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generic feature extraction parameters\n",
    "batch_size = 16\n",
    "num_neighbors = 20\n",
    "target_layer = \"blocks.11.attn.proj\"\n",
    "cache_dir = \"cache/flowers102\"\n",
    "\n",
    "# Make sure the cache directory exists\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Run the code on GPU if possible, or fallback on the CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052739fd-4941-49cb-8b51-996970b0a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/wsimoncini/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv1\n",
    "model = torch.hub.load(\"facebookresearch/dino:main\", \"dino_vitb16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8b5a0a-046f-49e1-9268-1992b39e3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_dataset = Flowers102(root=cache_dir, split=\"train\", download=True)\n",
    "test_dataset = Flowers102(root=cache_dir, split=\"test\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b90326-768a-421a-b4f8-4c9b44177385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-10 18:39:51,646:INFO]: initializing FUNGI wrapper...\n",
      "[2024-07-10 18:39:51,646:INFO]: estimating the model output dimensionality...\n",
      "[2024-07-10 18:39:51,865:INFO]: generating the projection matrix...\n",
      "/home/wsimoncini/.conda/envs/fungi-lib-clean/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "[2024-07-10 18:39:55,580:INFO]: running setup for extractor KLGradientsExtractor\n",
      "[2024-07-10 18:39:55,581:INFO]: running setup for extractor DINOGradientsExtractor\n",
      "[2024-07-10 18:39:55,581:INFO]: running setup for extractor SimCLRGradientsExtractor\n",
      "[2024-07-10 18:39:55,581:INFO]: computing the simclr negative batch\n",
      "[2024-07-10 18:39:58,013:INFO]: encoding 3136 samples...\n",
      "100%|██████████| 98/98 [00:07<00:00, 13.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Wrap the model using the FUNGI feature extractor\n",
    "fungi = FUNGIWrapper(\n",
    "    model=model,\n",
    "    target_layer=target_layer,\n",
    "    device=device,\n",
    "    use_fp16=True,\n",
    "    extractor_configs=[\n",
    "        KLConfig(),\n",
    "        DINOConfig(),\n",
    "        # You can configure the self-supervised objectives by passing arguments\n",
    "        # to their configuration objects. See each config dataclass in\n",
    "        # src/fungivision/config for more details\n",
    "        SimCLRConfig(num_patches=4, stride_scale=6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# You must call setup before extracting FUNGI features, as some objectives\n",
    "# may require some supporting data to compute the loss, e.g. the SimCLR\n",
    "# negative batch\n",
    "fungi.setup(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0375bb-2e37-4d87-82e0-2ce08cbe918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]/home/wsimoncini/.conda/envs/fungi-lib-clean/lib/python3.10/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/wsimoncini/.conda/envs/fungi-lib-clean/lib/python3.10/site-packages/torch/nn/functional.py:2976: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|██████████| 64/64 [01:40<00:00,  1.57s/it]\n",
      "100%|██████████| 385/385 [10:04<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract train and test FUNGI features and targets\n",
    "fungi_train_features, _ = extract_fungi_features(wrapper=fungi, dataset=train_dataset, batch_size=batch_size)\n",
    "fungi_test_features, _ = extract_fungi_features(wrapper=fungi, dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53408665-b36f-4d88-94f6-3841c4ec2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]/scratch-local/wsimoncini.6942228/ipykernel_3605794/446540400.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets.append(torch.tensor(batch_targets))\n",
      "100%|██████████| 64/64 [00:02<00:00, 24.25it/s]\n",
      "100%|██████████| 385/385 [00:07<00:00, 53.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract train and test DINO embeddings\n",
    "#\n",
    "# The DINO inference transform according to the original repo\n",
    "# https://github.com/facebookresearch/dino/blob/main/eval_knn.py#L32\n",
    "transform = tf.Compose([\n",
    "    tf.Resize(256, interpolation=3),\n",
    "    tf.CenterCrop(224),\n",
    "    tf.ToTensor(),\n",
    "    tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Re-initialize the datasets, as we need to specify the inference transform\n",
    "train_dataset = Flowers102(root=cache_dir, split=\"train\", download=True, transform=transform)\n",
    "test_dataset = Flowers102(root=cache_dir, split=\"test\", download=True, transform=transform)\n",
    "\n",
    "train_features, train_targets = extract_features(model=model, device=device, dataset=train_dataset, batch_size=batch_size)\n",
    "test_features, test_targets = extract_features(model=model, device=device, dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3428ffd-cd3f-4326-9a87-a7e9e49dc77b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluate both FUNGI and embedding in k-nearest neighbor evaluation, and report both the accuracy and the mean-per-class accuracy. We evaluate both gradient-only and gradients+embeddings FUNGI features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b72c8f-d6f0-4a66-97b8-d6c1b7414514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(\n",
    "    train_features: torch.Tensor,\n",
    "    test_features: torch.Tensor,\n",
    "    train_targets: torch.Tensor,\n",
    "    test_targets: torch.Tensor,\n",
    "    num_neighbors: int = 20,\n",
    "    normalize: bool = True\n",
    "):\n",
    "    if normalize:\n",
    "        test_features = nn.functional.normalize(test_features, dim=-1, p=2)\n",
    "        train_features = nn.functional.normalize(train_features, dim=-1, p=2)\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier(\n",
    "        n_neighbors=num_neighbors,\n",
    "        n_jobs=-1\n",
    "    ).fit(train_features, train_targets)\n",
    "\n",
    "    predictions = knn_classifier.predict(test_features)\n",
    "\n",
    "    correct_predictions = (predictions == np.array(test_targets)).sum()\n",
    "    \n",
    "    accuracy = correct_predictions / len(test_targets) * 100\n",
    "    mean_per_class_acc = mean_per_class_accuracy(\n",
    "        preds=predictions,\n",
    "        targets=test_targets\n",
    "    ) * 100\n",
    "    fungi_test_features\n",
    "\n",
    "    print(f\"the test accuracy was {round(accuracy, 2)}\")\n",
    "    print(f\"the mean per-class accuracy was {round(mean_per_class_acc, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44427617-99d4-4d81-b3ae-3618b82ecc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "the test accuracy was 73.88\n",
      "the mean per-class accuracy was 76.99\n",
      "---------------------------------------------\n",
      "FUNGI gradient-only features\n",
      "the test accuracy was 77.85\n",
      "the mean per-class accuracy was 80.94\n",
      "---------------------------------------------\n",
      "FUNGI gradient+embeddings features\n",
      "the test accuracy was 78.11\n",
      "the mean per-class accuracy was 81.38\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings\")\n",
    "\n",
    "eval(\n",
    "    train_features=train_features,\n",
    "    test_features=test_features,\n",
    "    train_targets=train_targets,\n",
    "    test_targets=test_targets,\n",
    "    num_neighbors=num_neighbors\n",
    ")\n",
    "\n",
    "print(\"---\" * 15)\n",
    "print(\"FUNGI gradient-only features\")\n",
    "\n",
    "eval(\n",
    "    train_features=fungi_train_features,\n",
    "    test_features=fungi_test_features,\n",
    "    train_targets=train_targets,\n",
    "    test_targets=test_targets,\n",
    "    num_neighbors=num_neighbors\n",
    ")\n",
    "\n",
    "print(\"---\" * 15)\n",
    "print(\"FUNGI gradient+embeddings features\")\n",
    "\n",
    "mixed_train_features = torch.cat([nn.functional.normalize(train_features, dim=-1, p=2), fungi_train_features], dim=-1)\n",
    "mixed_test_features = torch.cat([nn.functional.normalize(test_features, dim=-1, p=2), fungi_test_features], dim=-1)\n",
    "\n",
    "eval(\n",
    "    train_features=mixed_train_features,\n",
    "    test_features=mixed_test_features,\n",
    "    train_targets=train_targets,\n",
    "    test_targets=test_targets,\n",
    "    num_neighbors=num_neighbors\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fungi-env",
   "language": "python",
   "name": "fungi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
